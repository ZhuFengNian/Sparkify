{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify 项目 Workspace\n",
    "这个 Workspace 包括一个迷你的子数据集（128MB），是完整数据集（12GB）的一个子集。在将你的项目部署到云上之前，你可以自由使用 Workspace 来创建你的项目或用Spark来探索这个较小数据集。设置 Spark 集群的指南可以在选修 Spark 课程的内容里找到。\n",
    "\n",
    "你可以依照下面的步骤进行项目的数据分析和模型搭建部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, concat, desc, explode, lit, min, max, split, udf, isnull, udf, concat, col, desc, year, month, asc, count, avg, countDistinct\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Normalizer, PCA, RegexTokenizer, StandardScaler, StopWordsRemover, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载和清洗数据\n",
    "在这个 Workspace 中，小数据集的名称是 `mini_sparkify_event_data.json`.加载和清洗数据集，检查是否有无效或缺失数据——例如，没有userid或sessionid的数据。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[artist: string, auth: string, firstName: string, gender: string, itemInSession: bigint, lastName: string, length: double, level: string, location: string, method: string, page: string, registration: bigint, sessionId: bigint, song: string, status: bigint, ts: bigint, userAgent: string, userId: string]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkify_data = 'mini_sparkify_event_data.json'\n",
    "df = spark.read.json(sparkify_data)\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 features\n"
     ]
    }
   ],
   "source": [
    "names = df.schema.names\n",
    "print('There are {} features'.format(len(names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|          artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page| registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|  Martha Tilston|Logged In|    Colin|     M|           50| Freeman|277.89016| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|           Rockpools|   200|1538352117000|Mozilla/5.0 (Wind...|    30|\n",
      "|Five Iron Frenzy|Logged In|    Micah|     M|           79|    Long|236.09424| free|Boston-Cambridge-...|   PUT|NextSong|1538331630000|        8|              Canada|   200|1538352180000|\"Mozilla/5.0 (Win...|     9|\n",
      "|    Adam Lambert|Logged In|    Colin|     M|           51| Freeman| 282.8273| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|   Time For Miracles|   200|1538352394000|Mozilla/5.0 (Wind...|    30|\n",
      "|          Enigma|Logged In|    Micah|     M|           80|    Long|262.71302| free|Boston-Cambridge-...|   PUT|NextSong|1538331630000|        8|Knocking On Forbi...|   200|1538352416000|\"Mozilla/5.0 (Win...|     9|\n",
      "|       Daft Punk|Logged In|    Colin|     M|           52| Freeman|223.60771| paid|     Bakersfield, CA|   PUT|NextSong|1538173362000|       29|Harder Better Fas...|   200|1538352676000|Mozilla/5.0 (Wind...|    30|\n",
      "+----------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(names).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+---------+------+-------------+--------+---------+-----+--------------------+\n",
      "|              artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|\n",
      "+--------------------+---------+---------+------+-------------+--------+---------+-----+--------------------+\n",
      "|      Martha Tilston|Logged In|    Colin|     M|           50| Freeman|277.89016| paid|     Bakersfield, CA|\n",
      "|    Five Iron Frenzy|Logged In|    Micah|     M|           79|    Long|236.09424| free|Boston-Cambridge-...|\n",
      "|        Adam Lambert|Logged In|    Colin|     M|           51| Freeman| 282.8273| paid|     Bakersfield, CA|\n",
      "|              Enigma|Logged In|    Micah|     M|           80|    Long|262.71302| free|Boston-Cambridge-...|\n",
      "|           Daft Punk|Logged In|    Colin|     M|           52| Freeman|223.60771| paid|     Bakersfield, CA|\n",
      "|The All-American ...|Logged In|    Micah|     M|           81|    Long|208.29995| free|Boston-Cambridge-...|\n",
      "|The Velvet Underg...|Logged In|    Micah|     M|           82|    Long|260.46649| free|Boston-Cambridge-...|\n",
      "|        Starflyer 59|Logged In|    Colin|     M|           53| Freeman|185.44281| paid|     Bakersfield, CA|\n",
      "|                null|Logged In|    Colin|     M|           54| Freeman|     null| paid|     Bakersfield, CA|\n",
      "|            Frumpies|Logged In|    Colin|     M|           55| Freeman|134.47791| paid|     Bakersfield, CA|\n",
      "|        Britt Nicole|Logged In|    Micah|     M|           83|    Long| 229.8771| free|Boston-Cambridge-...|\n",
      "|                null|Logged In|    Micah|     M|           84|    Long|     null| free|Boston-Cambridge-...|\n",
      "|Edward Sharpe & T...|Logged In|    Colin|     M|           56| Freeman|223.58159| paid|     Bakersfield, CA|\n",
      "|               Tesla|Logged In|    Micah|     M|           85|    Long|201.06404| free|Boston-Cambridge-...|\n",
      "|                null|Logged In|    Micah|     M|           86|    Long|     null| free|Boston-Cambridge-...|\n",
      "|         Stan Mosley|Logged In|    Colin|     M|           57| Freeman|246.69995| paid|     Bakersfield, CA|\n",
      "|Florence + The Ma...|Logged In|    Micah|     M|           87|    Long|168.64608| free|Boston-Cambridge-...|\n",
      "|   Tokyo Police Club|Logged In|  Ashlynn|     F|            0|Williams| 166.1122| free|     Tallahassee, FL|\n",
      "|             Orishas|Logged In|    Colin|     M|           58| Freeman|222.22322| paid|     Bakersfield, CA|\n",
      "|             Ratatat|Logged In|    Micah|     M|           88|    Long|229.77261| free|Boston-Cambridge-...|\n",
      "+--------------------+---------+---------+------+-------------+--------+---------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(names[:9]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|method|           page| registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+------+---------------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|   PUT|       NextSong|1538173362000|       29|           Rockpools|   200|1538352117000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538331630000|        8|              Canada|   200|1538352180000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|       NextSong|1538173362000|       29|   Time For Miracles|   200|1538352394000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538331630000|        8|Knocking On Forbi...|   200|1538352416000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|       NextSong|1538173362000|       29|Harder Better Fas...|   200|1538352676000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538331630000|        8|      Don't Leave Me|   200|1538352678000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|       NextSong|1538331630000|        8|         Run Run Run|   200|1538352886000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|       NextSong|1538173362000|       29|Passengers (Old A...|   200|1538352899000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|Add to Playlist|1538173362000|       29|                null|   200|1538352905000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538173362000|       29|          Fuck Kitty|   200|1538353084000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538331630000|        8|   Walk On The Water|   200|1538353146000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   GET|    Roll Advert|1538331630000|        8|                null|   200|1538353150000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|       NextSong|1538173362000|       29|                Jade|   200|1538353218000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538331630000|        8|      Gettin' Better|   200|1538353375000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|      Thumbs Up|1538331630000|        8|                null|   307|1538353376000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|       NextSong|1538173362000|       29|   So-Called Friends|   200|1538353441000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538331630000|        8| You've Got The Love|   200|1538353576000|\"Mozilla/5.0 (Win...|     9|\n",
      "|   PUT|       NextSong|1537365219000|      217|Citizens Of Tomorrow|   200|1538353668000|\"Mozilla/5.0 (Mac...|    74|\n",
      "|   PUT|       NextSong|1538173362000|       29|           Represent|   200|1538353687000|Mozilla/5.0 (Wind...|    30|\n",
      "|   PUT|       NextSong|1538331630000|        8|              Swisha|   200|1538353744000|\"Mozilla/5.0 (Win...|     9|\n",
      "+------+---------------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(names[9:]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|level|\n",
      "+-----+\n",
      "| free|\n",
      "| paid|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT level FROM df_view\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|           page|   num|\n",
      "+---------------+------+\n",
      "|       NextSong|228108|\n",
      "|           Home| 14457|\n",
      "|      Thumbs Up| 12551|\n",
      "|Add to Playlist|  6526|\n",
      "|     Add Friend|  4277|\n",
      "|    Roll Advert|  3933|\n",
      "|          Login|  3241|\n",
      "|         Logout|  3226|\n",
      "|    Thumbs Down|  2546|\n",
      "|      Downgrade|  2055|\n",
      "+---------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT page, COUNT(*) AS num FROM df_view GROUP BY page ORDER BY num DESC\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|userID| num|\n",
      "+------+----+\n",
      "|      |8346|\n",
      "|    10| 795|\n",
      "|   100|3214|\n",
      "|100001| 187|\n",
      "|100002| 218|\n",
      "|100003|  78|\n",
      "|100004|1245|\n",
      "|100005| 216|\n",
      "|100006|  44|\n",
      "|100007| 520|\n",
      "|100008| 940|\n",
      "|100009| 671|\n",
      "|100010| 381|\n",
      "|100011|  23|\n",
      "|100012| 600|\n",
      "|100013|1392|\n",
      "|100014| 310|\n",
      "|100015|1050|\n",
      "|100016| 638|\n",
      "|100017|  75|\n",
      "+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT userID , COUNT(*) AS num FROM df_view GROUP BY userID ORDER BY userID ASC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|sessionID|num|\n",
      "+---------+---+\n",
      "|        1|714|\n",
      "|        2|  7|\n",
      "|        3| 38|\n",
      "|        4| 24|\n",
      "|        5| 58|\n",
      "|        6| 71|\n",
      "|        7|  1|\n",
      "|        8| 49|\n",
      "|        9|197|\n",
      "|       10|176|\n",
      "|       11| 47|\n",
      "|       12| 60|\n",
      "|       13|122|\n",
      "|       15|220|\n",
      "|       16| 39|\n",
      "|       17|171|\n",
      "|       18| 30|\n",
      "|       19|158|\n",
      "|       20| 29|\n",
      "|       21|138|\n",
      "+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT sessionID, COUNT(*) AS num FROM df_view GROUP BY sessionID ORDER BY sessionID ASC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 探索性数据分析\n",
    "当你使用完整数据集时，通过加载小数据集，在 Spark 中完成基础操作来实现探索性数据分析。在这个 Workspace 中，我们已经提供给你一个你可以探索的小数据集。\n",
    "\n",
    "### 定义客户流失\n",
    "\n",
    "在你完成初步分析之后，创建一列 `Churn` 作为模型的标签。我建议你使用 `Cancellation Confirmation` 事件来定义客户流失，该事件在付费或免费客户身上都有发生。作为一个奖励任务，你也可以深入了解 `Downgrade` 事件。\n",
    "\n",
    "### 探索数据\n",
    "你定义好客户流失后，就可以执行一些探索性数据分析，观察留存用户和流失用户的行为。你可以首先把这两类用户的数据聚合到一起，观察固定时间内某个特定动作出现的次数或者播放音乐的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286500"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 清除userId和sessionId喂na的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how = \"any\", subset = [\"userId\", \"sessionId\"])\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 清除userid为空的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278154"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.filter(df.userId!=\"\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义churn 函数，分析Cancellation Confirmation\n",
    "churn_func = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Churn\", churn_func(df.page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(artist='Martha Tilston', auth='Logged In', firstName='Colin', gender='M', itemInSession=50, lastName='Freeman', length=277.89016, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Rockpools', status=200, ts=1538352117000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30', Churn=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f74798160b8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74799ef668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#length 可视化\n",
    "data_len = df.select(\"length\").toPandas()\n",
    "data_len.plot(kind = \"hist\", bins = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#格式化时间\n",
    "def convertDatetime(data):\n",
    "    '''\n",
    "    Input: Dataset\n",
    "    Output: Dataset with converted registration date and hour \n",
    "    '''\n",
    "    # Convert registration date\n",
    "    get_date = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).strftime(\"%Y-%m-%d\"))\n",
    "    data = data.withColumn(\"registration_date\", get_date(data.registration))\n",
    "    # Convert hour\n",
    "    get_hour = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).strftime(\"%H\"))\n",
    "    data = data.withColumn(\"hour\", get_hour(data.ts))\n",
    "    \n",
    "    return data\n",
    "df = convertDatetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|registration_date|\n",
      "+-----------------+\n",
      "|       2018-08-23|\n",
      "|       2018-06-22|\n",
      "|       2018-08-24|\n",
      "|       2018-09-27|\n",
      "|       2018-11-26|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('registration_date').distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|                song|              artist|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|      You're The One|       Dwight Yoakam| 1122|\n",
      "|                Undo|            BjÃÂ¶rk| 1026|\n",
      "|             Revelry|       Kings Of Leon|  854|\n",
      "|       Sehr kosmisch|            Harmonia|  728|\n",
      "|Horn Concerto No....|Barry Tuckwell/Ac...|  641|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|              artist|count|\n",
      "+--------------------+-----+\n",
      "|       Kings Of Leon| 1841|\n",
      "|            Coldplay| 1813|\n",
      "|Florence + The Ma...| 1236|\n",
      "|       Dwight Yoakam| 1135|\n",
      "|            BjÃÂ¶rk| 1133|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 按照song 和arties排序\n",
    "df.dropna().groupBy(['song', 'artist']).count().sort(desc('count')).show(5)\n",
    "df.dropna().groupBy(['artist']).count().sort(desc('count')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程\n",
    "熟悉了数据之后，就可以构建你认为会对训练模型帮助最大的特征。要处理完整数据集，你可以按照下述步骤：\n",
    "- 写一个脚本来从小数据集中提取你需要的特征\n",
    "- 确保你的脚本可以拓展到大数据集上，使用之前教过的最佳实践原则\n",
    "- 在完整数据集上运行你的脚本，按运行情况调试代码\n",
    "\n",
    "如果是在教室的 workspace，你可以直接用里面提供的小数据集来提取特征。确保当你开始使用 Spark 集群的时候，把上述的成果迁移到大数据集上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFeatures(data):\n",
    "    '''\n",
    "    处理Gender, Thumps up, Thumps down, Listening time,Number of songs per user, free or paid user等特征\n",
    "    最终将处理之后的特征整合之后返回\n",
    "    '''\n",
    "    # Gender category进行转化\n",
    "    gender_num = data \\\n",
    "           .select('userId','gender')\\\n",
    "           .dropDuplicates() \\\n",
    "           .replace(['M','F'],['0','1'],'gender')\\\n",
    "           .select('userId',col('gender').cast('int'))\\\n",
    "           .withColumnRenamed('gender', 'gender_num') \n",
    "    \n",
    "    # 统计Thumbs up\n",
    "    thumbs_up = data \\\n",
    "             .select('userID','page') \\\n",
    "             .where(data.page == 'Thumbs Up') \\\n",
    "             .groupBy('userID') \\\n",
    "             .count() \\\n",
    "             .withColumnRenamed('count', 'thumbs_up') \n",
    "    \n",
    "    # 统计Thumps down\n",
    "    thumbs_down = data \\\n",
    "                 .select('userID','page') \\\n",
    "                 .where(data.page == 'Thumbs Down') \\\n",
    "                 .groupBy('userID') \\\n",
    "                 .count() \\\n",
    "                 .withColumnRenamed('count', 'thumbs_down')\n",
    "    \n",
    "    # 统计Listening Time的总和\n",
    "    listening_time = data \\\n",
    "            .select('userId','length') \\\n",
    "            .groupby(['userId']) \\\n",
    "            .sum() \\\n",
    "            .withColumnRenamed('sum(length)','listening_time')\n",
    "\n",
    "    # 计算每位user的song的数量\n",
    "    song_per_user = data \\\n",
    "                  .select(\"userId\",\"song\")\\\n",
    "                  .groupby(\"userId\")\\\n",
    "                  .count()\\\n",
    "                  .withColumnRenamed(\"count\",\"song_per_user\")\n",
    "    \n",
    "    # 将Free or paid category特征进行转换\n",
    "    level_num = data \\\n",
    "         .select('userId','level')\\\n",
    "         .replace(['free','paid'],['0','1'],'level')\\\n",
    "         .select('userId',col('level').cast('int'))\\\n",
    "         .withColumnRenamed('level', 'level_num') \n",
    "    \n",
    "    # 提取churn并命名为label，在后续的训练的时候需要lable，此处进行命名\n",
    "    churn = data \\\n",
    "        .select('userId', col('Churn').alias('label')) \\\n",
    "        .dropDuplicates()\n",
    "\n",
    "    # 整合所有特征\n",
    "    feature_data = song_per_user.join(gender_num,'userID','outer') \\\n",
    "              .join(thumbs_up,'userID','outer') \\\n",
    "              .join(thumbs_down, 'userID','outer') \\\n",
    "              .join(listening_time,'userID','outer') \\\n",
    "              .join(level_num,'userID','outer') \\\n",
    "              .join(churn,'userID','outer') \\\n",
    "              .drop('userID') \\\n",
    "              .fillna(0)\n",
    "\n",
    "\n",
    "    \n",
    "    return feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processFeatures(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+-----------+-----------------+---------+-----+\n",
      "|song_per_user|gender_num|thumbs_up|thumbs_down|   listening_time|level_num|label|\n",
      "+-------------+----------+---------+-----------+-----------------+---------+-----+\n",
      "|          381|         1|       17|          5|66940.89735000003|        0|    0|\n",
      "+-------------+----------+---------+-----------+-----------------+---------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformAndScale(data):\n",
    "    '''\n",
    "    对特征进行scale操作，使用StandardScaler进行处理\n",
    "    '''\n",
    "    # Transform 操作\n",
    "    cols = ['song_per_user', 'gender_num', 'thumbs_up', 'thumbs_down','level_num','listening_time']\n",
    "    assembler = VectorAssembler(inputCols=cols, outputCol=\"NumFeatures\")\n",
    "    dataAssemblered = assembler.transform(data)\n",
    "    \n",
    "    # Scale 操作\n",
    "    scaler = StandardScaler(inputCol=\"NumFeatures\", outputCol=\"features\", withStd=True)\n",
    "    scalerModel = scaler.fit(dataAssemblered)\n",
    "    data = scalerModel.transform(dataAssemblered)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= transformAndScale(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+-----------+-----------------+---------+-----+--------------------+--------------------+\n",
      "|song_per_user|gender_num|thumbs_up|thumbs_down|   listening_time|level_num|label|         NumFeatures|            features|\n",
      "+-------------+----------+---------+-----------+-----------------+---------+-----+--------------------+--------------------+\n",
      "|          381|         1|       17|          5|66940.89735000003|        0|    0|[381.0,1.0,17.0,5...|[0.18973652418087...|\n",
      "+-------------+----------+---------+-----------+-----------------+---------+-----+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模\n",
    "将完整数据集分成训练集、测试集和验证集。测试几种你学过的机器学习方法。评价不同机器学习方法的准确率，根据情况调节参数。根据准确率你挑选出表现最好的那个模型，然后报告在训练集上的结果。因为流失顾客数据集很小，我建议选用 F1 score 作为优化指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练和测试数据\n",
    "train, validation = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndValidateWithGivenModel(model,train=train,validation=validation):\n",
    "    #统计处理时间\n",
    "    start_time = time.time()\n",
    "    ##使用f1 score指标\n",
    "    f_score = MulticlassClassificationEvaluator(metricName='f1')\n",
    "    model_train = model.fit(train)\n",
    "    model_test = model_train.transform(validation)\n",
    "    #结果评估\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "    print(\"--------------------Start--------------------\\n\")\n",
    "    print(\"Model Name is:\", model)\n",
    "    print(\"Accuracy is:\")\n",
    "    print(evaluator.evaluate(model_test,{evaluator.metricName: 'accuracy'}))\n",
    "    print(\"F-1 score is :\")\n",
    "    print(evaluator.evaluate(model_test, {evaluator.metricName: 'f1'}))\n",
    "    print(\"Running %s seconds \\n\" % (time.time() - start_time))\n",
    "    print(\"---------------------End-------------------\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Start--------------------\n",
      "\n",
      "Model Name is: GBTClassifier_81e6ba272839\n",
      "Accuracy is:\n",
      "0.8610834835581526\n",
      "F-1 score is :\n",
      "0.8044951325485031\n",
      "Running 830.5971143245697 seconds \n",
      "\n",
      "---------------------End-------------------\n",
      "\n",
      "--------------------Start--------------------\n",
      "\n",
      "Model Name is: LogisticRegression_b339faed7959\n",
      "Accuracy is:\n",
      "0.8608192950829863\n",
      "F-1 score is :\n",
      "0.7964339801776644\n",
      "Running 105.86624765396118 seconds \n",
      "\n",
      "---------------------End-------------------\n",
      "\n",
      "--------------------Start--------------------\n",
      "\n",
      "Model Name is: RandomForestClassifier_ca5b7330c8f6\n",
      "Accuracy is:\n",
      "0.8608192950829863\n",
      "F-1 score is :\n",
      "0.7964339801776644\n",
      "Running 137.81644821166992 seconds \n",
      "\n",
      "---------------------End-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logist = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "gbt=GBTClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "model = [gbt,logist,forest]\n",
    "for i in model:\n",
    "    trainAndValidateWithGivenModel(i,train,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果分析，F1 score:\n",
    "GBTClassifier：0.8044951325485031\n",
    "LogisticRegression:0.7964339801776644\n",
    "RandomForestClassifier:0.7964339801776644\n",
    "从结果分析GBTClassifier有点过拟合，进一步对超参进行调节。准确率基本上一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进一步通过CrossValidator对GBTClassifier进行调参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainAndCrossValida(model=gbt,train=train,validation=validation):\n",
    "    #统计处理时间\n",
    "    start_time = time.time()\n",
    "    f1_score = MulticlassClassificationEvaluator(metricName='f1')\n",
    "    param_gbt = ParamGridBuilder()\\\n",
    "       .addGrid(gbt.maxIter,[5,10])\\\n",
    "       .addGrid(gbt.maxDepth,[5,10]) \\\n",
    "       .build()\n",
    "    crossval_model = CrossValidator(estimator=model,\n",
    "                           evaluator=f1_score,\n",
    "                           estimatorParamMaps=param_gbt,\n",
    "                           numFolds=3)\n",
    "    model_train = crossval_model.fit(train)\n",
    "    model_test = model_train.transform(validation)\n",
    "    #结果评估\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    print(\"Model is:\", model)\n",
    "    print(\"Accuracy:\")\n",
    "    print(evaluator.evaluate(model_test,{evaluator.metricName: 'accuracy'}))\n",
    "    print(\"F-1 score:\")\n",
    "    print(evaluator.evaluate(model_test, {evaluator.metricName: 'f1'}))\n",
    "    print(\"Running %s seconds \\n\" % (time.time() - start_time))\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "Model is: GBTClassifier_81e6ba272839\n",
      "Accuracy:\n",
      "0.8590787592465966\n",
      "F-1 score:\n",
      "0.8287466429244961\n",
      "Running 3296.849246740341 seconds \n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GBTClassifier_81e6ba272839"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAndCrossValida(gbt,train,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidator使用3次折叠，将生成3个（训练，测试）数据集对，每个对都使用2/3的数据进行训练，并使用1/3的数据进行测试.当数据集比较小的时候交叉验证可以“充分利用”有限的数据找到合适的模型参数，防止过度拟合.\n",
    "很明显当数据集较大的时候，导致整个训练的过程特别的漫长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 待改进：\n",
    "- 在进行训练的时候应该使用pipeline进行处理，这样整体的逻辑和代码比较简单明了\n",
    "- 通过CrossValidator进行处理，可以比较快速的得到较为优化的参数；\n",
    "- 调参数在时候需要平衡精度和召回率，不能只针对精度进行优化；\n",
    "- 尽可能将每一步的操作都概括为单个的函数；\n",
    "\n",
    "\n",
    "### 难点：\n",
    "- 由于对于模型的选择和参数设置没有很好的掌握，在数据集非常大的情况下每次运行话费的时间很长，导致花费的时间很久。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最后一步\n",
    "清理你的代码，添加注释和重命名变量，使得代码更易读和易于维护。参考 Spark 项目概述页面和数据科学家毕业项目审阅要求，确保你的项目包含了毕业项目要求的所有内容，并且满足所有审阅要求。记得在 GitHub 代码库里包含一份全面的文档——README文件，以及一个网络应用程序或博客文章。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
